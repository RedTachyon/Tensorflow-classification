{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_path = './data/train/X_train.txt'\n",
    "Y_path = './data/train/y_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    Reads data from the given path.\n",
    "    \n",
    "    Args:\n",
    "        path: str\n",
    "        \n",
    "    Returns:\n",
    "        data: np.ndarray\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        data = np.array([np.array(row.replace('  ', ' ').strip().split(' '), dtype=np.float32) for row in f])\n",
    "        \n",
    "    return data\n",
    "\n",
    "def read_labels(path):\n",
    "    \"\"\"\n",
    "    Reads labels from the given path.\n",
    "    \n",
    "    Args:\n",
    "        path: str\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray\n",
    "    \"\"\"\n",
    "    return np.genfromtxt(Y_path).reshape((-1, 1))\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Normalizes the input array to zero mean and unit variance across the 0th dimension.\n",
    "    \n",
    "    Args:\n",
    "        data: np.ndarray\n",
    "    \n",
    "    Returns:\n",
    "        normalized: np.ndarray, the argument normalized to zero mean and unit variance\n",
    "        mean, std: floats, mean and std of the original data\n",
    "    \"\"\"\n",
    "    mean = data.mean(0)\n",
    "    std = data.std(0)\n",
    "    \n",
    "    normalized = (data - mean) / std\n",
    "    \n",
    "    return normalized, mean, std\n",
    "\n",
    "def shuffle_data(X, Y):\n",
    "    \"\"\"\n",
    "    Randomly shuffle the data and labels across the zeroth axis (that is, across samples).\n",
    "    \n",
    "    Args:\n",
    "        X: np.ndarray, of shape (m, n) where m is the number of samples and n - features per sample\n",
    "        Y: np.ndarray, of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "        X, Y: shuffled data and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Shuffle the data\n",
    "    idx = np.random.permutation(np.arange(X.shape[0]))\n",
    "    return X[idx, :], Y[idx, :]\n",
    "    \n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    \"\"\"\n",
    "    Fixes the labels to start at 0 and have dtype = np.int\n",
    "    \"\"\"\n",
    "    return (labels - 1).astype(np.int)\n",
    "\n",
    "def get_data(X_path, Y_path, normalize=False):\n",
    "    \"\"\"\n",
    "    Extracts and normalizes the data and labels.\n",
    "    \"\"\"\n",
    "    X_train, Y_train = read_data(X_path), read_labels(Y_path)\n",
    "    Y_norm = preprocess_labels(Y_train)\n",
    "    if normalize:\n",
    "        X_norm, mean, std = normalize_data(X_train)\n",
    "        return X_norm, Y_norm, mean, std\n",
    "    else:\n",
    "        X_norm, mean, std = X_train, None, None\n",
    "    \n",
    "    \n",
    "    return X_norm, Y_norm, mean, std\n",
    "\n",
    "def train_dev_split(X, Y, ratio=0.1):\n",
    "    \"\"\"\n",
    "    Shuffles the data and splits it into a train set and a dev/validation set.\n",
    "    \"\"\"\n",
    "    X, Y = shuffle_data(X, Y)\n",
    "    \n",
    "    m_dev = int(ratio * X.shape[0])\n",
    "    \n",
    "    X_train, Y_train, X_dev, Y_dev = X[m_dev:,:], Y[m_dev:,:], X[:m_dev,:], Y[:m_dev,:]\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev\n",
    "\n",
    "def to_onehot(Y):\n",
    "    \"\"\"\n",
    "    Converts the labes to onehot format\n",
    "    \"\"\"\n",
    "    nb_classes = 6\n",
    "    targets = Y.reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    \n",
    "    return one_hot_targets\n",
    "\n",
    "def get_and_fix_data(X_path, Y_path, ratio=0.1):\n",
    "    \"\"\"\n",
    "    Convenience function for extracting data and doing all the necessary preprocessing.\n",
    "    \"\"\"\n",
    "    X_all, Y_all, _, _ = get_data(X_path, Y_path)\n",
    "    Y_all = to_onehot(Y_all)\n",
    "\n",
    "    X_train, Y_train, X_dev, Y_dev = train_dev_split(X_all, Y_all, ratio=ratio)\n",
    "    \n",
    "    return X_train, Y_train, X_dev, Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all, Y_all, _, _ = get_data(X_path, Y_path)\n",
    "Y_all = to_onehot(Y_all)\n",
    "\n",
    "X_train, Y_train, X_dev, Y_dev = train_dev_split(X_all, Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=float64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_split(X_all, Y_all, 0)[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
